---
title: "Introduction to Decision Trees"

---


Decision trees are a popular machine learning algorithm used for classification and regression. In this post, I give an introduction to decision trees. I used <a href="https://www.youtube.com/@DataTalksClub">DataTalksClub</a> as my main resource, and I highly recommend their channel.


<h1>What does a decision tree look like?</h1>
  
<p>A real-life tree consists of branches, roots, and leaves. </p>
  
<img src="https://user-images.githubusercontent.com/125330688/235809811-e27f37c8-f391-4840-95d2-53e971937b64.png" alt="legit_tree" width="400">

<p>Similarly, a decison tree consists of a root node, internal nodes, branches, and leaf nodes. In the image below, the node at the very top is called the "root node", the 5 nodes at the bottom labeled "okay" and "default" are called "leaf nodes". The rest of the nodes are called "internal nodes. The red and green arrows labeled True and False are called "branches". </p>

<img src="https://user-images.githubusercontent.com/125330688/235809824-60d97413-515b-48b5-8f53-5d1af9ea4490.png" alt="decision_tree" width="400">


<h1>How do each of the parts of a decision tree correspond to a dataset?</h1>
<h1>How are each of the nodes chosen? </h1>
<h1>What is overfitting and why is this an important consideration for decision trees?</h1>
<h1>What is impurity? </h1>
<h1>Decision tree learning algorithm</h1>

